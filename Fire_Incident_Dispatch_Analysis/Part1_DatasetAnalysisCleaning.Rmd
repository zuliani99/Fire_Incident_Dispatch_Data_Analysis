---
title: "Part 1 - Analysis & Dataset Cleaning"
author: "Zuliani Riccardo"
date: "17/1/2024"
output: 
  html_document: 
    toc: true
    toc_float: true
    number_sections: true
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE) #, cache=TRUE

# REMEMBER THO CHANCGE THE WORKING DIRECTORY
setwd("C:/Users/ricca/Desktop/UNI/Magistrale/Anno3/Statistical_Inference_and_Learning/SIL Projcet/Statistical_Inference_Learning_Project/Fire_Incident_Dispatch_Analysis")
```

# Loads & Install Packages

```{r}
# installation of packages in case the user has not installed yet
if (!require("nnet")) install.packages("nnet")
if (!require("MASS")) install.packages("MASS")
if (!require("e1071")) install.packages("e1071")
if (!require("class")) install.packages("class")
if (!require("leaps")) install.packages("leaps")
if (!require("glmnet")) install.packages("glmnet")
if (!require("car")) install.packages("car")
if (!require("caTools")) install.packages("caTools")
if (!require("pROC")) install.packages("pRoc")

if (!require("summarytools")) install.packages("summarytools")
if (!require("dplyr")) install.packages("dplyr")
if (!require("ggplot2")) install.packages("ggplot2")
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("lubridate")) install.packages("lubridate")
if (!require("mapview")) install.packages("mapview")
if (!require("leafpop")) install.packages("leafpop")
if (!require("sf")) install.packages("sf")
if (!require("geojsonio")) install.packages("geojsonio")
if (!require("leaflet")) install.packages("leaflet")
if (!require("broom")) install.packages("broom")
if (!require("gridExtra")) install.packages("gridExtra")

# laoding of packages
library(summarytools)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(lubridate)
library(mapview)
library(sf)
library(geojsonio)
library(leaflet) 
library(broom)
library(plotly)
library(gridExtra)
library(leafpop)
```


# Dataset description

The Fire Incident Dispatch Data file contains data that is generated by the Starfire Computer Aided Dispatch System. The data spans from the time the incident is created in the system to the time the incident is closed in the system. It covers information about the incident as it relates to the assignment of resources and the Fire Departmentâ€™s response to the emergency. To protect personal identifying information in accordance with the Health Insurance Portability and Accountability Act (HIPAA), specific locations of incidents are not included and have been aggregated to a higher level of detail.

In this analysis we have restricted the number of observations to the *last 50.000*, from 5th of September to 30th of the same month. 

The dataset is formed by the following columns:

1. **STARFIRE_INCIDENT_ID**: An incident identifier comprising the 5 character julian date, 4 character alarm box number, 2 character number of incidents at the box so far for the day, 1 character borough code , 4 character sequence number. 
2. **INCIDENT_DATETIME**: The date and time of the incident.
3. **ALARM_BOX_BOROUGH**: The borough of the alarm box.
4. **ALARM_BOX_LOCATION**: The location of the alarm box.
5. **ALARM_BOX**: The alarm box number.
6. **INCIDENT_BOROUGH**: The borough of the incident.
7. **ZIPCODE**: The zip code of the incident.
8. **POLICEPRECINCT**: The police precinct of the incident.
9. **CITYCOUNCILDISTRICT**: The city council district.
10. **COMMUNITYDISTRICT**: The community district.
11. **COMMUNITYSCHOOLDISTRICT**: The community school district.
12. **CONGRESSIONALDISTRICT**: The congressional district.
13. **ALARM_SOURCE_DESCRIPTION_TX**: The description of the alarm source.
14. **ALARM_LEVEL_INDEX_DESCRIPTION**: The alarm level index.
15. **HIGHEST_ALARM_LEVEL**: The highest alarm level.
16. **INCIDENT_CLASSIFICATION**: The incident classification.
17. **INCIDENT_CLASSIFICATION_GROUP**: The incident classification roll up group.

18. **FIRST_ASSIGNMENT_DATETIME**: The date and time of the first unit assignment.
19. **FIRST_ACTIVATION_DATETIME**: The date and time of the first unit acknowledgement of the assignment.
20. **FIRST_ON_SCENE_DATETIME**: The date and time of the first unit at the scene of the incident.
21. **INCIDENT_CLOSE_DATETIME**: The date and time that the incident was closed in the dispatch system.

22. **VALID_DISPATCH_RSPNS_TIME_INDC**: Indicates that the components comprising the generation of the DISPATCH_RESPONSE_SECONDS_QY are valid.
23. **DISPATCH_RESPONSE_SECONDS_QY**: The elapsed time in seconds between the INCIDENT_DATETIME and the FIRST_ASSIGNMENT_DATETIME.

24. **VALID_INCIDENT_RSPNS_TIME_INDC**: Indicates that the components comprising the generation of the INCIDENT_RESPONSE_SECONDS_QY are valid.
25. **INCIDENT_RESPONSE_SECONDS_QY**: The elapsed time in seconds between the INCIDENT_DATETIME and the FIRST_ON_SCENE_DATETIME.

26. **INCIDENT_TRAVEL_TM_SECONDS_QY**: The elapsed time in seconds between the FIRST_ASSIGNMENT_DATETIME and the FIRST_ON_SCENE_DATETIME.


27. **ENGINES_ASSIGNED_QUANTITY**: The number of engine units assigned to the incident.
28. **LADDERS_ASSIGNED_QUANTITY**: The number of ladder units assigned to the incident.
29. **OTHER_UNITS_ASSIGNED_QUANTITY**: The number of  units that are not engines or ladders that were assigned to the incident.


## Analysis Description

We will try create two different analysis.

1. The aim to predict the **INCIDENT_RESPONSE_SECONDS_QY** which is the time difference between the **FIRST_ON_SCENE_DATETIME** and **INCIDENT_DATETIME**.
2. The focus is to predict the **EMERGENCY_TIME** which is the time difference between the **FIRST_ON_SCENE_DATETIME** and **INCIDENT_CLOSE_DATETIME**. 

In both analysis tried to use a **linear regression** model, however we will see that the assumption for applying the linear regression are not meet, thus we will simplify our project moving into **classification**, dividing in two or more ranges the two responses. In addition of this we will perform data exploration and cleaning, studying the presence or not of pattern of NA values and invalid values.



# Data Exlporation and Cleaning

The first step is always to read the dataset, plot the first 5 observations and see its whole dimension.

```{r, cache=TRUE}
fire_data <- read.csv("datasets/Fire_Incident_Dispatch_Data_last_50k.csv")

head(fire_data)

dim(fire_data)
```

We ese `dfSummary` from `summarytool` in order to have a complete and clear summary of the dataset.
```{r}
print(dfSummary(fire_data, 
                plain.ascii  = FALSE, 
                style        = "multiline", 
                headings     = FALSE,
                graph.magnif = 0.8, 
                valid.col    = FALSE),
                method = 'render')
```

Now we decide to rename all the columns in order to be of smaller length once we plots some charts.
```{r}
fire_data <- fire_data %>%
  rename(id = STARFIRE_INCIDENT_ID, datetime = INCIDENT_DATETIME, al_borough = ALARM_BOX_BOROUGH,
    al_number = ALARM_BOX_NUMBER,al_location = ALARM_BOX_LOCATION, inc_borough = INCIDENT_BOROUGH,
    zipcode = ZIPCODE, pol_prec = POLICEPRECINCT, city_con_dist = CITYCOUNCILDISTRICT,
    commu_dist = COMMUNITYDISTRICT, commu_sc_dist = COMMUNITYSCHOOLDISTRICT,
    cong_dist = CONGRESSIONALDISTRICT, al_source_desc = ALARM_SOURCE_DESCRIPTION_TX,
    al_index_desc = ALARM_LEVEL_INDEX_DESCRIPTION, highest_al_level = HIGHEST_ALARM_LEVEL,
    inc_class = INCIDENT_CLASSIFICATION, inc_class_group = INCIDENT_CLASSIFICATION_GROUP,
    first_ass_datetime = FIRST_ASSIGNMENT_DATETIME, first_act_datetime = FIRST_ACTIVATION_DATETIME,
    first_onscene_datetime = FIRST_ON_SCENE_DATETIME, inc_close_datetime = INCIDENT_CLOSE_DATETIME, 
                   
    disp_resp_sec_qy = DISPATCH_RESPONSE_SECONDS_QY, disp_resp_sec_indc = VALID_DISPATCH_RSPNS_TIME_INDC,
    inc_resp_sec_qy = INCIDENT_RESPONSE_SECONDS_QY, inc_resp_sec_indc = VALID_INCIDENT_RSPNS_TIME_INDC,
                   
    inc_travel_sec_qy = INCIDENT_TRAVEL_TM_SECONDS_QY, 
                   
    engines_assigned = ENGINES_ASSIGNED_QUANTITY,
    ladders_assigned = LADDERS_ASSIGNED_QUANTITY, others_units_assigned = OTHER_UNITS_ASSIGNED_QUANTITY)
```


As we can see from the summary there are lots of work to do, in fact initially we identify the following problem:

1. Many `NA` values
2. Lots of predictors are characters and not factor
3. Many future factorial predictors have values that occurs very small time, this suggest that we can inglobe those in a bigger category
4. The differences of datatime have huge variation, we can think on scaling the relative values
5. Possible duplicate columns

We start by converting the non factorial columns into factorial one. Then we perform accurate data exploration and cleaning in each macro columns set.

```{r}
# set factorial
fire_data$inc_borough <- as.factor(fire_data$inc_borough)
fire_data$al_borough <- as.factor(fire_data$al_borough)
fire_data$al_source_desc <- as.factor(fire_data$al_source_desc)
fire_data$al_index_desc <- as.factor(fire_data$al_index_desc)
fire_data$highest_al_level <- as.factor(fire_data$highest_al_level)
fire_data$cong_dist <- as.factor(fire_data$cong_dist)

fire_data$disp_resp_sec_indc <- as.factor(fire_data$disp_resp_sec_indc)
levels(fire_data$disp_resp_sec_indc)<- c("N", "Y")

fire_data$inc_resp_sec_indc <- as.factor(fire_data$inc_resp_sec_indc)
levels(fire_data$inc_resp_sec_indc)<- c("N", "Y")

fire_data$inc_class_group <- as.factor(fire_data$inc_class_group)
fire_data$inc_class <- as.factor(fire_data$inc_class)
```



## Process Temporal Data

For the temporal data processing we employ a little of feature engineering. Indeed we decide to add the following predictors:

1. `day_type`: a factorial predictor to indicate if the incident day is a week day or not
2. `time_of_day`: a factorial predictor that indicates the range of time whenever the incident happens, so **Night** if the hour is between 0 and 6, **Morning** if the hour is between 6 and 12, **Afternoon** if the hour is between 12 and 18 and **Evening**  if the hour is between 18 and 24.
3. `emergency_min_qy`: which represents the difference between the `inc_close_datetime` and the `first_onscene_datetime`.
4. `working_hour`: indicates if the incident happened between 8AM and 7PM, so the classic working hour.

Moreover since we are dealing with datetime we also check if the time differences `inc_resp_sec_qy`, `inc_travel_sec_qy` and `disp_resp_sec_qy` are actually corrects, if not we replace them with the correct one, by performning the subtraction of the relative datetime (see dataset description).

Now we note that the maximum level of the time differences is very high to be considered as seconds so we decided to scale all the time differences in minutes.

```{r}
summary(fire_data %>% select(inc_resp_sec_qy, inc_travel_sec_qy, disp_resp_sec_qy))
```

```{r}
# scaling
fire_data$inc_resp_sec_qy <- fire_data$inc_resp_sec_qy / 60
fire_data$inc_travel_sec_qy <- fire_data$inc_travel_sec_qy / 60
fire_data$disp_resp_sec_qy <- fire_data$disp_resp_sec_qy / 60 

# renaming both quantity and indicator predictors for the two datetime 
fire_data <- fire_data %>% rename(inc_resp_min_qy = inc_resp_sec_qy, inc_travel_min_qy = inc_travel_sec_qy, disp_resp_min_qy = disp_resp_sec_qy, # quantity
                                  inc_resp_min_indc = inc_resp_sec_indc, disp_resp_min_indc = disp_resp_sec_indc) # indicator
```


Perform the datetime feature engineering that we have discussed before.

```{r}
# Process datetime column
fire_data$datetime <- mdy_hms(fire_data$datetime)
fire_data$first_ass_datetime <- mdy_hms(fire_data$first_ass_datetime)
fire_data$first_act_datetime <- mdy_hms(fire_data$first_act_datetime)
fire_data$first_onscene_datetime <- mdy_hms(fire_data$first_onscene_datetime)
fire_data$inc_close_datetime <- mdy_hms(fire_data$inc_close_datetime)


# checking if the differences are well computed if not change with the correct one

if (!identical(fire_data$inc_resp_min_qy, as.numeric(difftime(fire_data$first_onscene_datetime, fire_data$datetime, units="mins")))){
  fire_data$inc_resp_min_qy <- as.numeric(difftime(fire_data$first_onscene_datetime, fire_data$datetime, units="mins"))
}

if (!identical(fire_data$inc_travel_min_qy, as.numeric(difftime(fire_data$first_onscene_datetime, fire_data$first_ass_datetime, units="mins")))){
  fire_data$inc_travel_min_qy <- as.numeric(difftime(fire_data$first_onscene_datetime, fire_data$first_ass_datetime, units="mins"))
}

if (!identical(fire_data$disp_resp_min_qy, as.numeric(difftime(fire_data$first_ass_datetime, fire_data$datetime, units="mins")))){
  fire_data$disp_resp_min_qy <- as.numeric(difftime(fire_data$first_ass_datetime, fire_data$datetime, units="mins"))
}

# creating emergency_min_qy which describe the time taken by the firefighter to close the emergency after have been arrived to the location 
fire_data$emergency_min_qy <- as.numeric(difftime(fire_data$inc_close_datetime, fire_data$first_onscene_datetime, units="mins"))

# creating day_type
fire_data$day_type <- as.factor(ifelse(weekdays(fire_data$datetime) %in% c("sabato", "domenica"), "Weekend", "Weekday"))

# creating working_hour
fire_data$working_hour <- as.factor(ifelse(hour(fire_data$datetime) >= 19 | hour(fire_data$datetime) < 8, FALSE, TRUE))
  
# creating time_of_day
fire_data$time_of_day <- cut(
    hour(fire_data$datetime),
    breaks = c(0, 6, 12, 18, 24),
    labels = c("Night", "Morning", "Afternoon", "Evening"),
    include.lowest = TRUE,
    right = TRUE
)

# delete the datetime
fire_data$datetime <- NULL
```

Check the distribution of `time_of_day`

```{r}
table(fire_data$time_of_day)
```
```{r}
ggplot(data=fire_data %>% 
          group_by(time_of_day) %>%
          summarise(incident_number = n()), 
        aes(x=time_of_day, y=incident_number)) + 
      geom_bar(stat="identity", position=position_dodge()) +
      geom_text(aes(label=incident_number), vjust=1.6, color="white", position = position_dodge(0.9), size=3.5) +
      labs(title = "Time of the Day - Incident Count", x = "Time of the Day", y = "Incident Count")
```

From this we can see that the higher number of fire incident is registered from 12 PM to 18 PM, whereas the lower number of fire incident happened from the 00 AM to 06 AM.



Check the distribution of `day_type`

```{r}
table(fire_data$day_type)
```
```{r}
day_type_table <- table(fire_data$day_type)
day_type_table[1] <- day_type_table[1] / 5
day_type_table[2] <- day_type_table[2] / 2
day_type_table
```

And in proportion we can see that on average there is an higher number of fire incident on the week day respect to the week end days.


Check the distribution of `working_hour`

```{r}
table(fire_data$working_hour)
```
```{r}
table(fire_data$working_hour) / dim(fire_data)[1]
```

It seems like that there are slightly more incident during the working hour.



## Process Spatial Data

Rename the factor levels for the `inc_borough` and `al_borough`.

```{r}
fire_data <- fire_data %>% mutate(inc_borough = recode_factor(
      inc_borough, "BRONX" = "Bronx", "BROOKLYN" = "Brooklyn", "MANHATTAN" = "Manhattan",
      "QUEENS" = "Queens", "RICHMOND / STATEN ISLAND" = "Staten Island"),
                  
      al_borough = recode_factor(
      al_borough, "BRONX" = "Bronx", "BROOKLYN" = "Brooklyn", "MANHATTAN" = "Manhattan",
      "QUEENS" = "Queens", "RICHMOND / STATEN ISLAND" = "Staten Island"))
```

Regarding the Spatial Data we decide to keep the borough and also the congressional district since are the two predictors that have the least number of categories. Further in the section of data visualization we have a look on an interactive map of some relevant information for both aspects. 


## Merging Factors

At this point we merge some possible value from factorial predictors to make their value space of smaller size.

### Highest Alarm Level

Here we merge the following factorial values of `highest_al_level`: `All Hands Working`, `Second Alarm` and `Third Alarm` into `NonFirst Alarm`. But before doing so let's see the actual distribution of values.

```{r}
table(fire_data$highest_al_level)
```
As we can see the majority of the observations are of the type **First Alarm**, whereas the other observation reach 109 observation, thus we concatenate the less category values into a single one called **NonFirst Alarm**


```{r}
fire_data$highest_alarm_lev_new <- fire_data$highest_al_level
levels(fire_data$highest_alarm_lev_new) <- list(
  "First Alarm" = "First Alarm", 
  "NonFirst Alarm" = c("All Hands Working", "Second Alarm", "Third Alarm")
)

ctable(fire_data$highest_al_level, fire_data$highest_alarm_lev_new, prop = 'n', totals = FALSE, headings = FALSE)

fire_data$highest_al_level <- fire_data$highest_alarm_lev_new
fire_data$highest_alarm_lev_new <- NULL
```

### Alarm Index Description

Here we merge the following factorial values of `al_index_desc`: `Second Alarm`, `Third Alarm`, `7-5 (All Hands Alarm)`, `10-76 & 10-77 Signal (Notification Hi-Rise Fire)` and `10-75 Signal (Request for all hands alarm)` into `Others`. But before doing so let's see the actual distribution of values.

```{r}
table(fire_data$al_index_desc)
```

As we can see the two major category are **DEFAULT RECORD** and **Initial Alarm**, whereas the rest of categories occur very few time respect the main two, thus we decide again to merge them.

```{r}
fire_data$alarm_level_idx_new <- fire_data$al_index_desc
levels(fire_data$alarm_level_idx_new) <- list(
  "DEFAULT RECORD" = "DEFAULT RECORD",
  "Initial Alarm" = "Initial Alarm", 
  "Others" = c("Second Alarm", "Third Alarm", "7-5 (All Hands Alarm)", 
               "10-76 & 10-77 Signal (Notification Hi-Rise Fire)",
               "10-75 Signal (Request for all hands alarm)")
)

ctable(fire_data$al_index_desc, fire_data$alarm_level_idx_new, prop = 'n', totals = FALSE, headings = FALSE)

fire_data$al_index_desc <- fire_data$alarm_level_idx_new
fire_data$alarm_level_idx_new <- NULL
```

### Alarm Source Description

Here we merge the following factorial values of `al_source_desc`: `911`, `911TEXT`, `VERBAL`, `BARS`, `ERS`, `ERS-NC` and `SOL` into `Others`. But before doing so let's see the actual distribution of values.

```{r}
table(fire_data$al_source_desc)
```
We decide to maintain as original the highest four and merge the rest into a new category.

```{r}
fire_data$alarm_source_desc_new <- fire_data$al_source_desc
levels(fire_data$alarm_source_desc_new) <- list(
  "PHONE" = "PHONE",
  "EMS" = "EMS",
  "EMS-911" = "EMS-911",
  "CLASS-3" = "CLASS-3",
  "Others" = c("911", "911TEXT", "VERBAL", "BARS", "ERS", "ERS-NC", "SOL")
)

ctable(fire_data$al_source_desc, fire_data$alarm_source_desc_new, prop = 'n', totals = FALSE, headings = FALSE)

fire_data$al_source_desc <- fire_data$alarm_source_desc_new
fire_data$alarm_source_desc_new <- NULL
```

View again the dataset summary to see the applied changes.

```{r}
print(dfSummary(fire_data, 
                plain.ascii  = FALSE, 
                style        = "multiline", 
                headings     = FALSE,
                graph.magnif = 0.8, 
                valid.col    = FALSE),
                method = 'render')
```



## Dealing with Invalid Values
The next step is to deal invalid values and delete some un-useful predictors.


### Duplicate Columns

First of all we saw the possibility that `al_borough` and `inc_borough` represent the same column, let's check it.


```{r}
identical(fire_data$al_borough, fire_data$inc_borough)
```
The column ``al_borough` and `inc_borough` have the same sequence of values, so we can delete one of the two.

```{r remove al_borough}
fire_data <- fire_data %>% select(-c(al_borough))
```


### Constant value for all observations

Then we say that all observation in the dataset have the indicator predictor `disp_resp_min_indc` equal to *N*, let's check again and in affermative case then we can delete both columns.

```{r}
summary(fire_data$disp_resp_min_indc)
```


All our observations have non valid `disp_resp_min_indc` so we could delete both the column indicator and the respective column quantity `disp_resp_min_qy`. However we note that also in the original full dataset all the observation have the `disp_resp_min_indc` set to **N**, which is quite strange, and it seems like there is problem relative to the data acquisition, thus for the moment we decide to keep this time difference.



### Validity Column Check

Now we do a quick check also on the other indicator predictor `inc_resp_min_indc`

```{r}
summary(fire_data$inc_resp_min_indc)
```

But here we have some observations with valid `inc_resp_min_indc`, and we will consider only the valid one deleting the one that has a non valid attribute.

However before doing that let's see the distribution of `inc_resp_min_qy` around the borough.

```{r}
ggplot(data=fire_data %>% group_by(inc_borough, inc_resp_min_indc) %>% summarise(incident_number = n()), 
       aes(x=inc_borough, y=incident_number, fill=inc_resp_min_indc)) +
  geom_bar(stat="identity", position=position_dodge()) +
  geom_text(aes(label=incident_number), vjust=1.6, color="white",
            position = position_dodge(0.9), size=3.5) +
  scale_fill_brewer(palette="Paired") +
  labs(title = "Incident Count - Borouh - Valid Response Time in Minutes", x = "Borough", y = "Incident Number", fill = "Valid Response\n Time in Minutes")
```

We can see that the number of fire incident is higher for the valid response time in minutes with the top level from the Brooklyn borough. But it is much interesting observe the rateo between the valid and the non valid.

Here we see the rateo of valid `inc_resp_min_indc` in each borough:

```{r}
rateo_inc_resp_min_indc <- fire_data %>% 
  group_by(inc_borough, inc_resp_min_indc) %>% 
  summarise(incident_number = n()) %>% 
  mutate(ratio=incident_number/sum(incident_number))

ggplot(rateo_inc_resp_min_indc, aes(fill=inc_resp_min_indc, y=ratio, x=inc_borough)) + 
  geom_bar(position="fill", stat="identity") + 
  geom_text(aes(label=scales::percent(ratio)), position=position_fill(vjust=0.5)) +
  labs(title="Borough - Rateo Incident between Valid and Invalid",
       x="Borough",
       y="Rateo Incident between Valid and Invalid",
       fill="Valid Response\nTime in Minutes")

```

And we can see that Staten Island has the higher number of incidents with valid `inc_resp_min_indc` , whereas Manhattan has the lower number, but remember that the former has the lowest number of fire incident and the latter has the higher number of incident.

Now we do an additional analysis to see if there is some relation between the `inc_resp_min_indc` and a new predictor the `total_assigned_unit` which is the sum of all the assigned units. 

```{r}
fire_data$total_assigned_unit <- fire_data$engines_assigned + fire_data$ladders_assigned + fire_data$others_units_assigned

ggplot(fire_data %>% drop_na(), aes(total_assigned_unit, inc_resp_min_qy)) + 
  geom_point(aes(colour = inc_resp_min_indc), na.rm = TRUE)+
  #scale_color_gradient(na.value = NA) + 
  labs(title = "Total Assigned Units - Response Time In Minutes", x = "Total Assigned Units",
        y = "Response Time In Minutes", colour = "Valid Response\n Time in Minutes")
```

We note that the majority of fire incident that had been assigned a single units has a high invalid response time. Whereas for an higher number of total units the response time decrease and becomes valid.

So we decide to have a look on the distribution of total assigned units respect to the response time for the observation that have invalid response time, all grouped by incident class. 
```{r}
ggplot(fire_data %>% filter(inc_resp_min_indc == "N") %>% drop_na()
            , aes(total_assigned_unit, inc_resp_min_qy)) + 
  geom_point(aes(colour = inc_class_group)) +
  labs(title = "Total Assigned Units - Response Time In Minutes - Incidnet Class Group", x = "Total Assigned Units", y = "Response Time In Minutes", colour = "Incident Class Groups")
```

And we see a majority of observation being of the incident class **Medical Emergencies** having assigned a single units. A closer look to the distribution of invalid response time for each incident class group summarised by the count of incident conferm what we already see in the previous points chart.
```{r}
irt_i_class <- arrange(fire_data %>% filter(inc_resp_min_indc == "N") %>%
  group_by(inc_class_group) %>% summarise(incident_number = n()), desc(incident_number))
irt_i_class
```


Now we add a indicator column that tell us if the total assigned units is one or not. This would be useful in order to see possible relations.
```{r}
# add an additional predictor
fire_data$tua_is_one <- as.factor(ifelse(fire_data$total_assigned_unit == 1, TRUE, FALSE))
```

See the relative incident count for each incident class.
```{r}
irt_i_class_su <- arrange(fire_data %>% filter(inc_resp_min_indc == "N",  tua_is_one == TRUE) %>%
         group_by(inc_class_group) %>% summarise(incident_number = n()), desc(incident_number))
irt_i_class_su
```


And we found that majority of all observation if not almost the entire dataset records are from the **Medical Emergencies** with only ```r irt_i_class[1,2] - irt_i_class_su[1,2]``` incidents that have been assigned more than a single unit. Whereas almost all the other incidents are from the **NonMedical Emergencies** where in this case the incidents that have been assigned more than a single unit are more, so we have to take into account this higher amount of observations. Indeed we have ```r irt_i_class[2,2] - irt_i_class_su[2,2]``` **NonMedical Emergencies** incidents that have invalid response time and have been assigned more than a single units.


At this point we decide to view the presence or not of pattern of incident with invalid response time that belong to the **Medical Emergencies** class with a single units assigned, first by grouping by borough.
```{r}
tuaisone <- fire_data %>% 
        filter(inc_resp_min_indc == "N", inc_class_group == "Medical Emergencies") %>%
        group_by(inc_borough, tua_is_one) %>%
        summarise(incident_number = n())
```

Plot the bar chart.

```{r}
ggplot(data=tuaisone, 
       aes(x=inc_borough, y=incident_number, fill=tua_is_one)) +
  geom_bar(stat="identity", position=position_dodge()) +
  geom_text(aes(label=incident_number), vjust=1.5, color="black",
            position = position_dodge(0.9), size=3.5) +
  scale_fill_brewer(palette="Set1") +
  labs(title = "Total Assigned Units One or Not for Invaid Resp Min Time",
       x = "Borough", y = "Incident Count", fill = "Total Assigned\nUnits are One")
```
And we can see that Bronx, Brooklyn and Manhattan have more or less the same amount of incident with invalid response time in minutes with a single assigned units.

Now we continue this analysis fo the invalid response time by changing the focus on the type of incident class (the sub-category which is more precise) with a single total assigned units.

```{r, fig.height = 5, fig.width = 15}
ggplot(data=fire_data %>% 
        filter(inc_resp_min_indc == "N", inc_class_group == "Medical Emergencies", tua_is_one == TRUE) %>%
        group_by(inc_class, inc_borough) %>%
        summarise(incident_number = n()), 
       aes(x=inc_borough, y=incident_number, fill=inc_class)) + 
      geom_bar(stat="identity", position=position_dodge()) +
        geom_text(aes(label=incident_number), vjust=-0.5, color="black",
                  position = position_dodge(0.9), size=3) +
        scale_fill_brewer(palette="Set1") +
        labs(title = "Borough - Incident Counts - Incident Class -- for Total Assigned Units equal to 1 for Invalid Responde Time",
             x = "Borough", y = "Incident Counts", fill = "Incident Class Group")
```


And we found that the majority of the incident that respect these circumstances are mostly identified as **Medical - EMS Link 10-91** and **Medical - PD Link 10-91**.

Thanks to the [10code](http://www.fdnewyork.com/10code.asp) site we found a description of the two emergency codes:

1. **10-91 Medical Emergency EMS** - Fire Unit Not Required - To be transmitted through borough dispatcher by the responding unit when the fire Unit is canceled enroute due to EMS on scene, or EMS downgrades the job to a segment that does not require a Fire Unit response. Note: This signal shall be used only for medical emergency incidents. EMS  we are sure that stands for *Emergency Medical Services*.

2. **10-91 Medical Emergency PD** - Fire Unit Not Required - To be transmitted through borough dispatcher by the responding unit when the fire Unit is canceled enroute due to PD on scene, or PD downgrades the job to a segment that does not require a Fire Unit response. Note: This signal shall be used only for medical emergency incidents. PD we think that stands for *Police Department*.

Thus we can trust this information since they make sense and consider only the observations that have `inc_resp_min_indc == "Y"`.


Now we can look for the **NonMedical Emergencies** since are the second category for number of observation that by first see the distribution of its incident class.

Here we print the top 5 classes which respect the following conditions: `inc_resp_min_indc == "N", inc_class_group == "NonMedical Emergencies"`

```{r}
print(head(arrange(fire_data %>% 
        filter(inc_resp_min_indc == "N", inc_class_group == "NonMedical Emergencies") %>%
        group_by(inc_class) %>%
        summarise(incident_number = n()), desc(incident_number))))
```

And we found that the majority of non valid `inc_resp_min_indc` that are **Non-Medical Emergency** are from the incident class group equal to **Assist Civilian - Non-Medical**.

```{r}
ggplot(data=fire_data %>% 
          filter(inc_resp_min_indc == "N", inc_class == "Assist Civilian - Non-Medical") %>%
          group_by(inc_borough) %>%
          summarise(incident_number = n()), 
        aes(x=inc_borough, y=incident_number)) + 
      geom_bar(stat="identity", position=position_dodge()) +
      geom_text(aes(label=incident_number), vjust=1.6, color="white", position = position_dodge(0.9), size=3.5) +
      labs(title = "Assist Civilian - Non-Medical / Invalid Response / More than 1 Units", x = "Borough", y = "Incident Count")
```

We can see that except Staten Island the amount of incident is pretty constant.


So for a stake of sempicity we decided to trust the indicator of incident response time and thus considering only the observations that have `inc_resp_min_indc == "Y"`.

```{r}
fire_data <- fire_data %>% filter(inc_resp_min_indc == "Y")
dim(fire_data)
```

### Does the Incident Classes are unique for each Incident Class Group?

Now we want to know how many `inc_class` are summarized in each `inc_class_group` and if there are any intersection between any incident classes. We perform this analysis to be sure that each `inc_class_group` is referred to a single `inc_class`.


```{r}
unique_category <- fire_data%>% 
  group_by(inc_class) %>%
  summarise(unique_maincategory = n_distinct((inc_class_group)))

conflict <- unique_category %>% filter(unique_maincategory > 1)

if (dim(conflict)[1] == 0){
  print("There are NO conflict between main and sub-category")
} else {
  print("There are conflict between main and sub-category")
}
```

So we are sure that each sub category has a unique main-category incident.

At this point to be more clear we display each main class with each respective sub-class.

```{r}
for (variable in levels(fire_data$inc_class_group)) {
  non_zero_table <- table(subset(fire_data, inc_class_group == variable)$inc_class)
  cat(variable, "\n")
  print(non_zero_table[non_zero_table != 0])
  cat("\n")
}
```




# Dealing With Missing Data

At this point is essential to deal with NA values, trying to find the presence of possible relation with predictors. First things first let's recap the number of NA values for each columns that we have at the moment.

```{r}
colSums(is.na(fire_data))
```

## Geographical Columns

Here we will check if there is a pattern on the absence of values in the following predictors: `zipcode`, `pol_prec`, `city_con_dist`, `commu_dist`, `commu_sc_dist` and `cong_dist`.

```{r}
na_locations <- fire_data %>%
  filter(is.na(zipcode) | is.na(pol_prec) | is.na(city_con_dist) | is.na(commu_dist) | is.na(commu_sc_dist) | is.na(cong_dist))
```


```{r, fig.height = 5, fig.width = 10}
ggplot(data=na_locations %>% 
        group_by(inc_class_group, inc_borough) %>%
        summarise(incident_number = n()), 
       aes(x=inc_borough, y=incident_number, fill=inc_class_group)) + geom_bar(stat="identity", position=position_dodge()) +
        geom_text(aes(label=incident_number), vjust=-0.5, color="black",
                  position = position_dodge(0.9), size=3.5) +
        scale_fill_brewer(palette="Set1") +
        labs(title = "NA Locations Columns", x = "Borough", y = "Incident Count", fill = "Incident Class Group")
```


By the Bar Chart we note that the majority of observations that have at least one of the location predictors to NA are of the incident class group **NonMedical Emergency**, **Medical Emergencies** and **Non Medical MFAs**. 

Here we verify if the proportion of NA is equally distributed around each borough.
```{r}
table(na_locations$inc_borough) / table(fire_data$inc_borough)
```
And we found that Brooklyn has a lower percentage of NA location observation respect the others that are constant between them.

Thus we compute the same process but this time looking into the incident class group, like before we would like to have a constant distribution among all classes.
```{r}
table(na_locations$inc_class_group) / table(fire_data$inc_class_group)
```

However by looking at the proportion with the original dataset around the 40% of the whole observations of type **NonMedical MFAs** have at least one of the location columns to NA. Let's investigate.

In the original dataset this is the distribution of incident class for the NonMedical MFA incident class group.
```{r}
fd_nm_mfa_cl <- table(subset(fire_data, inc_class_group == "NonMedical MFAs")$inc_class)
fd_nm_mfa_bro <- table(subset(fire_data, inc_class_group == "NonMedical MFAs")$inc_borough)

fd_nm_mfa_cl <- fd_nm_mfa_cl[fd_nm_mfa_cl != 0]
fd_nm_mfa_cl
```

And this is the distribution  of incident class for the NonMedical MFA incident class group, but this time w.r.t. the subset of incidents that have at least one locaton column to NA.
```{r}
na_nm_mfa_cl <- table(subset(na_locations, inc_class_group == "NonMedical MFAs")$inc_class)
na_nm_mfa_bro <- table(subset(na_locations, inc_class_group == "NonMedical MFAs")$inc_borough)

na_nm_mfa_cl <- na_nm_mfa_cl[names(fd_nm_mfa_cl)]
na_nm_mfa_cl
```
And we can clearly see that the observations of category **Non-Medical MFA - ERS** are the main.


```{r}
na_nm_mfa_cl / fd_nm_mfa_cl
```
And more interestingly the **97% of all the Non-Medical MFA - ERS** observations in the entire dataset have one of the location attribute equal to NA.

```{r}
na_nm_mfa_bro / fd_nm_mfa_bro
```
And from here we can see that about the 78% of the observations that are NonMedical - MFAs that have at least one district column attribute to NA are from the RICHMOND / STATEN ISLAND. Also BRONX has about half of the NonMedical - MFAs observations that have at least one district column to NA.


```{r}
ggplot(data=na_locations %>%
         filter(inc_class == "Non-Medical MFA - ERS") %>%
         group_by(inc_borough) %>%
         summarise(incident_count = n()), 
      aes(x=inc_borough, y=incident_count)) + 
      geom_bar(stat="identity", position=position_dodge()) +
      geom_text(aes(label=incident_count), vjust=1.6, color="white", position = position_dodge(0.9), size=3.5) +
      labs(title = "Non-Medical MFA - ERS", x = "Borough", y = "Incident Count")
```

Finally we have that we have a lower number of **Non-Medical MFA - ERS** for Queens and Staten Istand.

So concluding **NonMedical MFA** stands for **Non Medical - Medical First Aid**, unfortunately we are not able to find the meaning of **ERS**, even if we think that could be possible be connected with something regarding the respiratory system like ERS: Emergency Respiratory System. And thus we think that these observations have NA location column by the same reason of the previously discussed **10-91 Medical Emergency**. However these are all suppositions, maybe by contacting the NYC Firefighters Department by mail should make things much clear.

Again for stake of semplicity we have assumed that the observations that have at least one NA locations are randomly spreaded among the dataset.


## Assigned Units Column

```{r}
print(fire_data %>%
  filter(is.na(engines_assigned) | is.na(ladders_assigned) | is.na(others_units_assigned)))
  
```

We can easily remove this observations, since it not appear any pattern and are only 4.

## First Act Datetime

Now we look into First Act Datetime and see if there is any pattern with the other columns.

```{r}
na_first_act_datetime <- fire_data %>% filter(is.na(first_act_datetime))
```

```{r}
print(arrange(na_first_act_datetime %>% group_by(inc_class, inc_borough) %>% summarise(incident_count = n()), desc(incident_count)))
```


```{r}
ggplot(data=na_first_act_datetime %>% 
        group_by(inc_class_group, inc_borough) %>%
        summarise(incident_count = n()), 
    aes(x=inc_borough, y=incident_count, fill=inc_class_group)) +
    geom_bar(stat="identity", position=position_dodge()) +
    geom_text(aes(label=incident_count), vjust=1.6, color="white", position = position_dodge(0.9), size=3.5) +
    labs(title = "NA First Act Date", x = "Borough", y = "Incident Count", fill = "Incident Class Group")
```

Seems to be random and thus there is no pattern that motivate the presence of NA values in `first_act_datetime`.


## Performing na.omit

**At this point we can omit the NA values.**

```{r}
fire_data_new <- na.omit(fire_data)
```


**And the un-usefull predictors** including `disp_resp_min_indc` and `inc_travel_min_qy` by since these two information are contained in `inc_resp_min_qy.` 

```{r}
fire_data_new <- fire_data_new %>% select(-c(zipcode, pol_prec, city_con_dist, commu_dist, al_location,
                                             commu_sc_dist, first_ass_datetime, first_act_datetime,
                                             first_onscene_datetime, inc_close_datetime, inc_resp_min_indc,
                                             disp_resp_min_indc, inc_travel_min_qy, disp_resp_min_qy, 
                                             id, al_number, inc_class))
```

We decide to remove also the incident class since it contains too much category values which are summarised in the incident class group.

```{r}
print(dfSummary(fire_data_new, 
                plain.ascii  = FALSE, 
                style        = "multiline", 
                headings     = FALSE,
                graph.magnif = 0.8, 
                valid.col    = FALSE),
                method = 'render')
```



# Data Visaulisation

In this section we will have a look on additional data visualisation in order to better understand how the predictors behaves. We divide this section in multiple subsection each focus on a relative subset of columns.

See the final columns that we have:
```{r}
names(fire_data_new)
```


We divide the data visualisation in the following subsections:

1. **Location Information**
2. **Alarm Information**
4. **Assigned Units Information**
3. **Time Information**
5. **Day Information**

In each section analysis we will use both response: `inc_resp_min_qy` adn `emergency_time_qy`.


## Location Information

Here we study the `inc_borough` and `cong_dist` columns for both responses.

### Incident Borough
```{r}
ggplot(fire_data_new,
       aes(x = inc_borough, y = inc_resp_min_qy, color = inc_class_group)) +
  geom_boxplot() +
  labs(title = "Borough - Incident Minutes Response Time - Incident Class",
       x = "Borough", y = "Incident Minutes Response Time", color = "Incident Class")
```
Here we can see that the response time is pretty the same around all borough for each incident class, indeed there is a slightly fast response respect to the other class for the **Structural Fires** as expected. The the highest number of outliers are from the **Medical** and **NonMedical Emergencies**.

```{r}
ggplot(fire_data_new,
       aes(x = inc_borough, y = emergency_min_qy, color = inc_class_group)) +
  geom_boxplot() +
  labs(title = "Borough - Emergency Minutes Time - Incident Class",
       x = "Borough", y = "Emergency Minutes Time", color = "Incident Class")
```

Like before the **Structural Fires** require lots of time but only in some drastic cases identified by the outliers since on average they require even less time respect other categories. 

### Congressional District

```{r}
bp1 <- ggplot(fire_data_new,
       aes(x = cong_dist, y = inc_resp_min_qy)) +
  geom_boxplot() +
  labs(title = "Cong District - EmergencyMin Time",
       x = "Cong District", y = "Emergency Min Time")

bp2 <- ggplot(fire_data_new,
       aes(x = cong_dist, y = emergency_min_qy)) +
  geom_boxplot() +
  labs(title = "Cong District - Emergency Min Time",
       x = "Cong District", y = "Emergency Minutes Time")

grid.arrange(bp1, bp2, ncol = 2)
```

Here we can't see any particular relevent information since on average we have the same distribution of time for all congressional district.

## Alarm Information

Here we study the `al_source_desc`, `al_index_desc` and `highest_al_level` columns for both responses.

### Alarm Source Description
```{r}
ggplot(fire_data_new,
       aes(x = al_source_desc, y = inc_resp_min_qy, color = inc_class_group)) +
  geom_boxplot() +
  labs(title = "Alarm Source Description - Incident Minutes Response Time - Incident Class",
       x = "Alarm Source Description", y = "Incident Minutes Response Time", color = "Incident Class")
```
With this boxplot we can understand that there are many outliers for emergencies called via phone, in particular **NonMedical Emergencies**. Also in both **EMS** and **EMS-911** there are many outliers for the Medical Emergencies. As expected then for emergencies called via **EMS-911** we do not find both **Fires** emergencies and **NonMedical MFAs**.

```{r}
ggplot(fire_data_new,
       aes(x = al_source_desc, y = emergency_min_qy, color = inc_class_group)) +
  geom_boxplot() +
  labs(title = "Alarm Source Description - Emergency Minutes Time - Incident Class",
       x = "Alarm Source Description", y = "Emergency Minutes Time", color = "Incident Class")
```
Now the first thing that we see is the high amount of outliers for the emergencies called via phone that are structural fires, indeed on average the emergency time is higher for that alarm source category. An other interesting fact is for **CLASS-3** the **NonMedical MFAs** have a big inter-quantile range, since we have few information for that particular class.

### Alarm Index Description
```{r}
ggplot(fire_data_new,
       aes(x = al_index_desc, y = inc_resp_min_qy, color = inc_class_group)) +
  geom_boxplot() +
  labs(title = "Alarm Index Description - Incident Minutes Response Time - Incident Class",
       x = "Alarm Index Description", y = "Incident Minutes Response Time", color = "Incident Class")
```
Again we can see many outliers for the two major class, and for the **Initial Alarm** we do not have any **Medical** and **NonMedical MFAs** emergencies. For the **Others** class like in the previous cans the inter-quantile range for the **NonStructural Fires** is big since in the merged category we do no have many observations.

```{r}
ggplot(fire_data_new,
       aes(x = al_index_desc, y = emergency_min_qy, color = inc_class_group)) +
  geom_boxplot() +
  labs(title = "Alarm Index Description - Emergency Minutes Time - Incident Class",
       x = "Alarm Index Description", y = "Emergency Minutes Time", color = "Incident Class")
```
Interestingly here we can see that around all the emergency with index level **DEFAULT RECORD** have very thin inter-quantile range with also low outliers, respect to the **Initial Alarm** and Others category level.

### Highest Alarm Level
```{r}
ggplot(fire_data_new,
       aes(x = highest_al_level, y = inc_resp_min_qy, color = inc_class_group)) +
  geom_boxplot() +
  labs(title = "Highest Alarm Level - Incident Minutes Response Time - Incident Class",
       x = "Highest Alarm Level", y = "Incident Minutes Response Time", color = "Incident Class")
```
Pretty all emergency of First Alarm have the same amount of response time with particular outliers for **Medical** and **NonMedical Emergencies** and also for **NonMedical MFAs**, whereas for **NonFirst Alarm** since we have few observation there for the **NonStructural Fire** we have a big range of interquantile.

```{r}
ggplot(fire_data_new,
       aes(x = highest_al_level, y = emergency_min_qy, color = inc_class_group)) +
  geom_boxplot() +
  labs(title = "Highest Alarm Level - Emergency Minutes Time - Incident Class",
       x = "Highest Alarm Level", y = "Emergency Minutes Time", color = "Incident Class")
```

Similarly to the previous subsection here all the emergency with highest alarm level to First Alarm have a low emergency time in particular **Medical** and **NonMedical MFAs**, again we have a significative number of outliers for this class. Regarding **NonFirst Level** we have few observations and that is why the emergency time is so different respect to the other class. Even if the longest time taken emergencies are a structural fire with highest alarm level **NonFirst Alarm**.



## Assigned Units Information

Here we study the `total_assigned_unit` and `tua_is_one` columns for both responses.


### Total Units Assigned
```{r}
ggplot(fire_data_new,
       aes(x = total_assigned_unit, y = inc_resp_min_qy, color = inc_class_group)) +
  geom_point(aes(color = inc_class_group)) +
  labs(title = "Total Units Assigned - Incident Minutes Response Time - Incident Class",
       x = "Total Units Assigned", y = "Incident Minutes Response Time", color = "Incident Class")
```
Whereas here as described in a previous similar chart, the total assigned units and the incident response time in minutes appear to be inversely proportional, with the contradistinction of structural fires that have many assigned units and low response time and Non Medical Emergencies that have low assigned units and high response time.


```{r}
ggplot(fire_data_new,
       aes(x = total_assigned_unit, y = emergency_min_qy, color = inc_class_group)) +
  geom_point(aes(color = inc_class_group)) +
  labs(title = "Total Units Assigned - Emergency Minutes Time - Incident Class",
       x = "Total Units Assigned", y = "Emergency Minutes Time", color = "Incident Class")
```
Here we can see that the Structural Fire incident have lots of variance directly and seems be a directly proportional relationship between the total assigned units and the Emergency Time. For the NonMedical Emergencies they are clustered and then for the Medical Emergencies we can see that they have been mostly assigend a single units.





### Total Assigned Units is One

```{r}
ggplot(fire_data_new,
       aes(x = tua_is_one, y = inc_resp_min_qy, color = inc_class_group)) +
  geom_boxplot() +
  labs(title = "Total Assigned Unit is 1 - Incident Minutes Response Time - Incident Class",
       x = "Total Assigned Unit is 1", y = "Incident Minutes Response Time", color = "Incident Class")
```
Here we can see a quite difference respect to having a total assigned unit equal to one and not, indeed every incident class have a higher mean value for the incident which had been assigend a single units.

```{r}
ggplot(fire_data_new,
       aes(x = tua_is_one, y = emergency_min_qy, color = inc_class_group)) +
  geom_boxplot() +
  labs(title = "Total Assigned Unit is 1 - Emergency Minutes Time - Incident Class",
       x = "Total Assigned Unit is 1", y = "Emergency Minutes Time", color = "Incident Class")
```

And in this case we can see that there is less variation on the emergency time response for the incident that had been assigned a single units, respect to the incident with more units assigned. And as expected the **Structural Fires** with more than one units are the type of incident with most outliers given their severity.

## Time Information

Here we study the relation of `inc_resp_min_qy` against `emergency_time_qy`.


```{r}
ggplot(fire_data_new,
       aes(x = inc_resp_min_qy, y = emergency_min_qy, color = inc_class_group)) +
  geom_point(aes(color = inc_class_group)) +
  labs(title = "Incident Minutes Response Time - Emergency Minutes Time - Incident Class",
       x = "Incident Minutes Response Time", y = "Emergency Minutes Time", color = "Incident Class")
```

Here we can see many different distribution with the relation that the less the response time is the higher is the time taken to close the emergency.

Since we can't understand much by this chart we decide to plot the density of each incident class group for both response.

```{r}
ggplot(fire_data_new, aes(x = inc_resp_min_qy, fill = inc_class_group)) +
  geom_density(alpha = 0.3) + xlim(0, 20) +
  labs(title = " Density Incident Minutes Response Time - Incident Class",
       x = "Incident Minutes Response Time", y = "Density", fill = "Incident Class")
```
In this density chart we can see that the distribution of **Incident Response Time** for each incident class seems to behave like a **Log-Norm distribution**.
We limit the x axis in order to be able to understand the distribution otherwise it will result in a very thin curve so not much easy to understand.

```{r}
ggplot(fire_data_new, aes(x = emergency_min_qy, fill = inc_class_group)) +
  geom_density(alpha = 0.5) + xlim(0, 75) +
  scale_fill_brewer(palette="Set1") +
  labs(title = "Density Emergency Response Time - Incident Class",
       x = "Emergency Response Time", y = "Density", fill = "Incident Class")
```
Similarly as before also here the distribution of **Incident Time** for each incident class seems to behave like a **Log-Norm distribution**.
Again lke before we limit the x axis in order to be able to understand the distribution otherwise it will result in a very thin curve so not much easy to understand.



## Day Information
Here we study the `day_type`, `working_hour` and `time_of_day` columns for both responses.

### Day Type
```{r}
ggplot(fire_data_new,
       aes(x = day_type, y = inc_resp_min_qy, color = inc_class_group)) +
  geom_boxplot() +
  labs(title = "Day Type - Incident Minutes Response Time - Incident Class",
       x = "Day Type", y = "Incident Minutes Response Time", color = "Incident Class")
```
Speaking about the day we can't see any relevant pattern here except that it appears in the weekend we have a lower number of outliers for all the incident class.

```{r}
ggplot(fire_data_new,
       aes(x = day_type, y = emergency_min_qy, color = inc_class_group)) +
  geom_boxplot() +
  labs(title = "Day Type - Emergency Minutes Time - Incident Class",
       x = "Day Type", y = "Emergency Minutes Time", color = "Incident Class")
```
Here there is any kind of patters that we can recondunct to the day type for the emergency time taken.

### Working Hour
```{r}
ggplot(fire_data_new,
       aes(x = working_hour, y = inc_resp_min_qy, color = inc_class_group)) +
  geom_boxplot() +
  labs(title = "Working Hour - Incident Minutes Response Time - Incident Class",
       x = "Working Hour", y = "Incident Minutes Response Time", color = "Incident Class")
```
Even for the working hourwe can't see any pattern regarding the incident response time.

```{r}
ggplot(fire_data_new,
       aes(x = working_hour, y = emergency_min_qy, color = inc_class_group)) +
  geom_boxplot() +
  labs(title = "Working Hour - Emergency Minutes Time - Incident Class",
       x = "Working Hour", y = "Incident Minutes Time", color = "Incident Class")
```
And even for the emergency time taken.

### Day Time
```{r}
ggplot(fire_data_new,
       aes(x = time_of_day, y = inc_resp_min_qy, color = inc_class_group)) +
  geom_boxplot() +
  labs(title = "Day Time - Incident Minutes Response Time - Incident Class",
       x = "Day Time", y = "Incident Minutes Response Time", color = "Incident Class")
```
Here we can't see any relevant pattern except the fact that we have an higher number of outliers in the afternoon for the **Medical**, **NonMedical Emergencies** and **Structural Fires**.

```{r}
ggplot(fire_data_new,
       aes(x = time_of_day, y = emergency_min_qy, color = inc_class_group)) +
  geom_boxplot() +
  labs(title = "Day Time - Emergency Minutes Time - Incident Class",
       x = "Day Time", y = "Incident Minutes Time", color = "Incident Class")
```
Here interestingly we can see that the longest time taken emergencies are **Structural Fires** and they happened in the **Night** and in the **Morning**. Except this we do not have any pattern.




### Maps Visualization

In this section we plot additional data visualization focus on the geographical visualization of the New York borough and congressional distirct with relative predictors. In order to do so we load an additional datasets:

1. The **fdny-firehouse-listing.csv** is a dataset that includes the geographical informations of every firefighter stations in the NYC, including again *latitude* and *longitude*.
2. **NYC_BoroughBoundaries.geojson** is the spatial dataframe that includes the geometry of each boroughs
3. **Congressiona_Districts.geojson** is the spatial dataframe that includes the geometry of each congressional districts


```{r}
firefighter_stations <- read.csv("datasets/fdny-firehouse-listing.csv")

head(firefighter_stations)
```

```{r}
summary(firefighter_stations)
```


We now start with the firefighter stations dataset. By first making a copy of the `fire_data_new` and setting the borough from the `firefighter_stations` dataset to factor in order to be easily merged with the copied fire_data dataset.

```{r}

# make a copy of the fire_data
fire_data_for_ffs <- fire_data_new

fire_data_for_ffs <- fire_data_for_ffs %>% rename(borough = inc_borough)

firefighter_stations$Borough <- as.factor(firefighter_stations$Borough)
firefighter_stations <- firefighter_stations %>% rename(borough = Borough)

# remove the na values from firefighter_stations
firefighter_stations <- na.omit(firefighter_stations)
```

Now we want to get the number of firefighter station for each borough.

```{r}
stations_borough <- firefighter_stations %>%
                    group_by(borough) %>%
                    summarise(number_of_stations = n())
```

Now we want to get a summary of the incident count, the number of station and the incident per station of each borough in order to have a general view of the New York City situation.

This step is done twice we have to group both for **borough** and then for **congressional district**.

```{r}
count_inc_brough <- fire_data_for_ffs %>% group_by(borough) %>% summarise(incident_count = n())
count_inc_cdist <- fire_data_for_ffs %>% group_by(cong_dist) %>% summarise(incident_count = n())

stations_borough$incident_per_station <- round(count_inc_brough$incident_count / stations_borough$number_of_stations, digits = 3)

count_inc_brough <- merge(count_inc_brough, stations_borough, by="borough")

count_inc_brough
```

Now we convert the `firefighter_station` data frame into a **Spartial Data Frame** to contains the geometry points.
```{r firefighter_stations_sdf}
firefighter_stations_sdf <- st_as_sf(firefighter_stations, coords = c("Longitude", "Latitude"), crs = 4326)
head(firefighter_stations_sdf)
```

#### Downloand of the geojson files

At this point we download the `.geojson` files that contain all the geometry of each borough in order to have a cool maps visualization of NYC.

Here we load the **NYC_BoroughBoundaries.geojson**.

```{r}
geoj_nyc_borough <- geojson_read("datasets/NYC_BoroughBoundaries.geojson",  what = "sp")
geoj_nyc_borough <- setNames(geoj_nyc_borough, c("borough_code", "borough", "shape_area", "shape_leng"))
geoj_nyc_borough$borough <- as.factor(geoj_nyc_borough$borough)
geoj_nyc_borough$borough_code <- NULL
head(geoj_nyc_borough)
```

And here the **Congressiona_Districts.geojson**.
```{r}
geoj_nyc_cdist <- geojson_read("datasets/Congressional_Districts.geojson",  what = "sp")
geoj_nyc_cdist$cong_dist <- as.factor(geoj_nyc_cdist$cong_dist)
head(geoj_nyc_cdist)
```

And now we merge `geoj_nyc_borough` with `count_inc_brough` maintaining the **Spartial Data Frame** type.

```{r}
geoj_nyc_borough@data = data.frame(geoj_nyc_borough@data, count_inc_brough[match(geoj_nyc_borough@data$borough, count_inc_brough$borough),])
geoj_nyc_borough@data$borough.1 <- NULL # remove the added column
```

Here we are making the same step as before but this this with the `geoj_nyc_cdist` merging via `cong_dist`, again maintaining the **Spartial Data Frame** type.

```{r}
geoj_nyc_cdist@data = data.frame(geoj_nyc_cdist@data, count_inc_cdist[match(geoj_nyc_cdist@data$cong_dist, count_inc_cdist$cong_dist),])
geoj_nyc_cdist@data$cong_dist.1 <- NULL # remove the added column
```

And finally we can plot the interactive maps using the `mapview` function.

First for Incident Borough:

```{r}
mapview(list(firefighter_stations_sdf, geoj_nyc_borough),
        zcol = list(NULL, "incident_count"),
        legend = list(FALSE, TRUE),
        homebutton = list(FALSE, TRUE),
        layer.name = list(NULL, "Incidents Count"),
        popup = list(popupTable(firefighter_stations_sdf), popupTable(geoj_nyc_borough)),
        alpha.regions = 0.5, aplha = 1)
```

And then for Congressional District:

```{r}
mapview(geoj_nyc_cdist,
        zcol = "incident_count",
        legend = TRUE,
        popup = popupTable(geoj_nyc_cdist),
        homebutton = TRUE,
        layer.name = "Incidents Count",
        alpha.regions = 0.5, aplha = 1)
```



# Before Doing some Models

As suggested by the professor we have opted to linear regression using as response:

1- `inc_resp_min_qy` 
2- `emergency_min_qy`

Initially we were thinking to solve a multi-classification / binary classification problem for the `inc_class_group`, however we were considering all the time difference predictors that are a future information w.r.t. the `inc_class_group` in prediction time, so it doesn't make much sense to use them, and it is possible also that they will result in super predictors. That's way we decided to grab the professor suggestion.

For both analysis we transform the relative response in **log scale** in order to simulate the behaviour of the Log-Norm distribution. Of course we have to verify that the linearty assumption are meet.

So first things first let's check if there are some observations that have at least one of the two possible responses equal to zero, if so we have to remove then in order to apply next the log transformation.

```{r}
summary(fire_data_new %>% select(inc_resp_min_qy, emergency_min_qy))
```

Remove them.
```{r}
fire_data_new <- fire_data_new %>% filter(emergency_min_qy != 0)
```


Then we have to check the presence of correlation in the continuous predictors and if so deleting one or more of them. Thus here we are doing an initial chec of **multicollinearity** problems only in the numerical variable before once we create our for the future models. In order to do so compute the square of the correlation matrix.

```{r}
round(cor(fire_data_new %>% dplyr::select(where(is.numeric)))^2, digits=3)
```
As we can see `total_assigned_unit` is heavily correlated to the other counts since it is the sum of those, thus deceide to remove the sum of units. Continuing we note also that lot's of time difference are correlated to each other, whoever it is obvious since some of them include other smaller difference, these measures will be managed soon once we deal with the two type of analysis.

```{r}
fire_data_new <- fire_data_new %>% select(-c(total_assigned_unit))
```


Next before creating any model have to split the cleaned dataset into *train* and *test*, with 80% of the whole dataset for the train set and the remaining 20% for the test set.
We want to mention that it would be better to perform cross validation using the entire data but for stake of simplicity and time we decide to opt for the classic train-test split. 

```{r}
set.seed(43)
split <- sample.split(fire_data_new, SplitRatio = 0.8)

# Create training and testing sets
fire_data.train <- subset(fire_data_new, split == TRUE)
fire_data.test <- subset(fire_data_new, split == FALSE)

rownames(fire_data.train) <- NULL
rownames(fire_data.test) <- NULL

dim(fire_data.train)
dim(fire_data.test)
```

Save the cleaned train and test dataframe for the next part of the analysis.

```{r}
write.csv(fire_data.train, "datasets/fire_data_clean.train.csv", row.names=FALSE)
write.csv(fire_data.test, "datasets/fire_data_clean.test.csv", row.names=FALSE)
```

Please go to the **Part 2 - Linear Regression** to continue the analysis.

